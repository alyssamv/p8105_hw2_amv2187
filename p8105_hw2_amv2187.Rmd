---
title: "p8105_hw2_amv2187"
author: "Alyssa Vanderbeek"
date: "5 October 2018"
output: github_document
---

## Problem 1


```{r}
knitr::opts_chunk$set(echo = TRUE)

library(readxl)
library(p8105.datasets)
library(tidyverse)
```

```{r data_clean, warning=FALSE, }
transit_data_clean = read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", col_types = cols()) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>%
  mutate(entry = recode(entry, 'YES' = TRUE, 'NO' = FALSE))

str(transit_data_clean) # display head of transit dataset
```

The cleaned dataset contains information about subway stations: the station name, the line it runs, its latitude and longitudinal location, the routes it services, whether entry exists and of what kind (stairs vs. elevator), and whether the station is ADA compliant. To learn and clean the data, I first imported and standardized the column names. I looked at the list of columns to understand what variables are available. Then I examined the unique values in a few of the columns to get a sense of how many distinct values there were. Lastly, I checked whether or not there were any missing values in the "Route 1" column. This would determine whether there were any stations (row entries) that had no routes associated. This would have been redundant and I would filter these rows out of the dataset. None were found. After cleaning the data as instructed, the dataset dimension are `r nrow(transit_data_clean)` rows by `r ncol(transit_data_clean)` columns. As of now, this dataset is not tidy.

```{r}
# number of distinct stations, defined by both station name and line
n_distinct_stations = transit_data_clean %>%
  distinct(station_name, line) %>%
  nrow

# number of ADA compliant stations
n_ada_compliant_stations = transit_data_clean %>%
  distinct(station_name, line, ada) %>%
  filter(ada == TRUE) %>%
  nrow

# proportion of stations entrances/exits without vending allow entrance
prop_no_vending_yes_entrance = transit_data_clean %>%
  filter(vending == 'NO') %>%
  summarise(sum(entry) / nrow(.))
  
```

There are `r n_distinct_stations` distinct stations, of which `r n_ada_compliant_stations` are ADA compliant. Of the stations that do not have vending, `r round(prop_no_vending_yes_entrance * 100, 0)`% allow entrance.

```{r}
# create tidy dataset
transit_data_tidy = transit_data_clean %>%
  gather(key = 'route', value = 'train', route1:route11) %>%
  mutate(route = substr(route, 6, nchar(route))) %>%
  distinct %>%
  filter(!is.na(train))

str(transit_data_tidy)

# number of stations that service the A train
A_train_station = transit_data_tidy %>%
  filter(train == 'A') %>%
  distinct %>%
  nrow

# number of stations that serive the A train and are ADA compliant
ADA_compliant_A_train = transit_data_tidy %>%
  filter(train == 'A', ada == TRUE) %>%
  distinct %>%  
  nrow
```

Additionally, `r A_train_station` stations service the A train, of which `r ADA_compliant_A_train` are ADA compliant.


## Problem 2

```{r}
## Mr. Trash Wheel data
trash_wheel_data = read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
    sheet = "Mr. Trash Wheel", range = cell_cols(1:14)) %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster) & month %in% month.name) %>%  # only dumpster-specific rows; i.e. dumpster number specified and row values are not totals
  mutate(sports_balls = as.integer(round(sports_balls)))

str(trash_wheel_data) # display column names and type

## Precipitation data
# 2016
precipitation_2016 = readxl::read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
    sheet = "2016 Precipitation", skip = 1) %>%
  janitor::clean_names() %>%
  filter(!is.na(month)) %>%
  mutate(year = '2016')

str(precipitation_2016)

# 2017
precipitation_2017 = readxl::read_excel("data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
    sheet = "2017 Precipitation", skip = 1) %>%
  janitor::clean_names() %>%
  filter(!is.na(month) & !is.na(total)) %>%
  mutate(year = '2017')

str(precipitation_2017)

# Combined both years
precipitation_combined = bind_rows(precipitation_2016, precipitation_2017) %>%
  mutate(month = month.name[month]) # create month as character with labels January through December

str(precipitation_combined)
```

The trash wheel dataset contains information about dumpsters that are sent to a waste-to-energy facility once they become full. Over the course of about `r round(difftime(max(trash_wheel_data$date), min(trash_wheel_data$date), units = 'days')/365)` years, `r nrow(trash_wheel_data)` were filled and transported to the facility. For each dumpster, information was collected regarding its weight, volume, and the type of waste it contained. This includes the number of glass bottles, plastic bags, and sports balls, to name a few. For example, from this data we know that the median number of sports balls collected in 2016 was `r trash_wheel_data %>% filter(year == '2016') %>% summarise(median_sports_balls = median(sports_balls))`. The number of homes that each dumpster powered is also estimated.  

Notably, dumpsters are filled more frequently in periods of precipitation. The precipitation dataset contains the total rainfall (in inches) for each month in the years 2016 and 2017. The average rainfall in 2016 was `r round(mean(precipitation_2016$total), 2)` inches, with a high of `r max(precipitation_2016$total)` inches in `r month.name[which(precipitation_2016$total == max(precipitation_2016$total))]`, and a low of `r min(precipitation_2016$total)` inches in `r month.name[which(precipitation_2016$total == min(precipitation_2016$total))]`. In 2017, precipitation data was missing for September through December. The average rainfall was `r round(mean(precipitation_2017$total), 2)` inches, with a high of `r max(precipitation_2017$total)` inches in `r month.name[which(precipitation_2017$total == max(precipitation_2017$total))]`, and a low of `r min(precipitation_2017$total)` inches in `r month.name[which(precipitation_2017$total == min(precipitation_2017$total))]`. The total precipitation in 2017 (for January through August) was `r sum(precipitation_2017$total)` inches.


## Problem 3

```{r}
data("brfss_smart2010") 

brfss_cleaned = brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == 'Overall Health') %>%
  select(-class, -topic, -question, -sample_size, -confidence_limit_low:-geo_location) %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>%
  mutate(excellent_or_very_good = excellent + very_good)

str(brfss_cleaned)
```

```{r}
num_unique_locations = brfss_cleaned %>%
  distinct(locationdesc) %>%
  nrow

# which states are not included in the dataset?
missing_states = which(!(state.abb %in% unique(brfss_cleaned$locationabbr)))

# are there any 'extra' states?
extra_locns = unique(brfss_cleaned$locationabbr)[which(!(unique(brfss_cleaned$locationabbr) %in% state.abb))]

## Function to get the mode(s) of a given variables (column)
Modes <- function(x) {
  t = which(table(x) == max(table(x)))
  return(paste(names(t), collapse = ','))
}

most_common_state = Modes(brfss_cleaned$locationabbr)
```

`r brfss_cleaned %>% distinct(locationdesc) %>% nrow` distinct locations were surveyed in the BRFSS data, and every state including Washington, DC is represented. `r state.name[match(most_common_state, state.abb)]` was observed most frequently. 

In 2002, the median proportion "Excellent" responses was `r brfss_cleaned %>% filter(year == 2002) %>% summarise(m = median(excellent, na.rm = T))`.

```{r}
# Histogram of "Excellent" responses in 2002
brfss_cleaned %>%
  filter(year == 2002) %>%
  ggplot(., aes(x = excellent)) +
  geom_histogram() +
  labs(
    title = 'Nationwide "Excellent" responses (2002)',
    y = 'Number of counties',
    x = 'Proportion of "Excellent" responses'
  ) +
  theme_bw()

# Scatterplot of "Excellent" responses in New York and Queens counties 2002-2010
brfss_cleaned %>%
  filter(grepl('New York County|Queens County', locationdesc) == T) %>%
  ggplot(., aes(x = year, y = excellent, color = locationdesc)) +
  geom_point() +
  geom_smooth(method = 'loess', se = F) +
  labs(
    title = 'Proportion of "Excellent" responses 2002-2010',
    y = 'Proportion of "Excellent" responses',
    x = 'Year'
  ) +
  viridis::scale_color_viridis(
    name = "Location",
    discrete = TRUE
  ) +
  theme_bw() +
  theme(legend.position = "bottom")
```

